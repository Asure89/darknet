
#[net]
# Testing
# batch=1
# subdivisions=1
# Training
batch=32
subdivisions=2
width=640
height=352
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.00005
burn_in=200
max_batches = 956633
policy=steps
steps=866633,876633,896633
scales=10,.5,.2

#0
[convolutional]
batch_normalize=1
filters=16
size=3
stride=1
pad=1
activation=leaky

# Downsample
#1
[convolutional]
batch_normalize=1
filters=32
size=3
stride=2
pad=1
activation=leaky

#2
[convolutional]
batch_normalize=1
filters=16
size=1
stride=1
pad=1
activation=leaky

#3
[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

#4
[shortcut]
from=-3
activation=linear

# Downsample
#5
[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=leaky
stopbackward=1

#6
[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=leaky

#7
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

#8
[shortcut]
from=-3
activation=linear

#9
[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=leaky

#10
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

#11
[shortcut]
from=-3
activation=linear

# Downsample
#12
[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=leaky

#13
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

#14
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

#15
[shortcut]
from=-3
activation=linear

#16
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

#17
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

#18
[shortcut]
from=-3
activation=linear

#19
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

#20
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

#21
[shortcut]
from=-3
activation=linear

#22
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

#23
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

#24
[shortcut]
from=-3
activation=linear

#25
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

#26
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

#27
[shortcut]
from=-3
activation=linear

#28
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

#29
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

#30
[shortcut]
from=-3
activation=linear

# Downsample
#31
[convolutional]
batch_normalize=1
filters=256
size=3
stride=2
pad=1
activation=leaky

#32
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

#33
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

#34
[shortcut]
from=-3
activation=linear


#35
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

#36
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

#37
[shortcut]
from=-3
activation=linear

#38
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

#39
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

#40
[shortcut]
from=-3
activation=linear

#41
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

#42
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

#43
[shortcut]
from=-3
activation=linear

#44
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

#45
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

#46
[shortcut]
from=-3
activation=linear

#47
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

#48
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

#49
[shortcut]
from=-3
activation=linear

# Downsample
# 50

[convolutional]
batch_normalize=1
filters=512
size=3
stride=2
pad=1
activation=leaky


#51
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

#52
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

#53
[shortcut]
from=-3
activation=linear

#54
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

#55
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

#56
[shortcut]
from=-3
activation=linear

#57
[convolutional]
batch_normalize=1

filters=256
size=1
stride=1
pad=1
activation=leaky

#58
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

#59
[shortcut]
from=-3
activation=linear

#60
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

#61
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1

filters=512
activation=leaky

#62
[convolutional]
batch_normalize=1

filters=256
size=1
stride=1
pad=1
activation=leaky

#63
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1



filters=512
activation=leaky

#64
[route]
layers = 48

#65
[convolutional]
batch_normalize=1
size=3
stride=2
pad=1
filters=256
activation=leaky

#66
[route]
layers = 63,65

#67
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=relu

#68
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=linear

#69
[convolutional]
batch_normalize=1
size=1
stride=1
pad=0



filters=256
activation=linear

#70
[convolutional]
size=1
stride=1
pad=0
filters=27
activation=linear


[yolo]
mask = 6,7,8
anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326
classes=4
num=9
jitter=.3
ignore_thresh = .5
truth_thresh = 1
random=0

#-3
[route]
layers = 29

#-2
[convolutional]
batch_normalize=1
filters=256
size=3
stride=2
pad=1
activation=leaky


# +1
[route]
layers = -1, 48



[convolutional]
batch_normalize=1
size=1
stride=1
pad=0




filters=256
activation=relu

#3
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=linear

#4
[convolutional]
batch_normalize=1
size=1
stride=1
pad=0
filters=256
activation=linear
#5
[convolutional]
size=1
stride=1
pad=0
filters=27
activation=linear


[yolo]
mask = 3,4,5
anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326
classes=4
num=9
jitter=.3
ignore_thresh = .5
truth_thresh = 1
random=0


# -3
[route]
layers = 10

#-2
[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=leaky


#+1
[route]
layers = -1, 29


#+2
[convolutional]
batch_normalize=1
size=1
stride=1
pad=0
filters=256
activation=relu

#+3
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=linear

#+4
[convolutional]
batch_normalize=1
size=1
stride=1
pad=0
filters=256
activation=linear

#+5
[convolutional]
size=1
stride=1
pad=0
filters=27
activation=linear


[yolo]
mask = 0,1,2
anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326
classes=4
num=9
jitter=.3
ignore_thresh = .5
truth_thresh = 1
random=0
